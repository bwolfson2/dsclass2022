{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaTzHRkCbf-X"
   },
   "source": [
    "To open notebook in Colab please click below:\n",
    "<a href=\"https://colab.research.google.com/github/bwolfson2/dsclass2022/blob/main/Module_2_Supervised_Learning/2%20Supervised%20segmentation.ipynb\" target=\"_parent\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" /> </a>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o27tIlWJbf-f",
    "outputId": "37707040-3cc1-4314-e7a6-73bc8950d164",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If opening in colab run this cell\n",
    "#!git clone https://github.com/bwolfson2/roger_2022\n",
    "#%cd roger_2022/Taste/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W2pCzDSbf-i"
   },
   "source": [
    "<span style=\"font-family: Palatino; font-size: 40px; color: purple\">\n",
    "             A sampling of some data science\n",
    "</span>\n",
    "\n",
    "\n",
    "Spring 2022 - Instructors: Roger M. Stein and Ben Wolfson\n",
    "\n",
    "Teaching Assistant: Ben Wolfson\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8u8aHhWbf-l"
   },
   "source": [
    "# <span style=\"font-family: Palatino; font-size: 30px; color: purple\"> Set-up and housekeeping</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8u8aHhWbf-l"
   },
   "source": [
    "## <span style=\"font-family: Palatino; font-size: 25px; color: purple\">Some general imports</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a ton of packages that make doing complicated stuff very easy. We won't discuss how to install packages, or give a detailed list of what packages exist, but we will give a brief description about how they are used. \n",
    "\n",
    "An easy way to think of why package are useful is by thinking: \"**Python packages give us access to MANY functions**\".\n",
    "\n",
    "Packages contain pre-defined functions (built-in) that make our life easier!  We've seen pre-defined functions before, for example, the funciton 'str()' that we used to convert numbers into strings in the Python Basics notebook.\n",
    "\n",
    "In this class we will use five packages very frequently: `pandas`, `sklearn`, `matplotlib`,  `seaborn`, and `numpy`:\n",
    "\n",
    "- **`pandas`** is a data manipulation package. It lets us store data in data frames. More on this soon.\n",
    "- **`sklearn`** is a machine learning and data science package. It lets us do fairly complicated machine learning tasks, such as running regressions and building classification models with only a few lines of code. (Nice!)\n",
    "- **`statsmodels.api`** is a statistical and econometrics package that is newer than, but more \"statistcal\" than `sklearn`. It has two main advantages over `sklearn` (a) a more intuitive set of reporting and analysis tools that include a number of advanced statistical and econometric techniques for time series, regime-switching and other applications; and (b) a formula-based (vs. matrix/vector) representation of models (as in R), which makes experimenting with data transformations much easier. It is Roger's first choice for anything involving time-series, generalized linear models or complex model designs in Python.  You should note that it uses a different set of conventions for model representation (but it is easy to write an `sklearn` wrapper if you prefer - see the `patsy` package). It lets us do fairly complicated statistical and econometric tasks, such as building statistical models with only a few lines of code. (Nice!)\n",
    "- **`matplotlib`** lets you make plots and graphs directly from your code.  This can be a secret weapon when combined with notebooks, as you can very easily rerun analyses on different data or with slightly different code, and the graphs can just appear magically.  (Ok, always easier said than done, but you get the idea.)\n",
    "- **`seaborn`** an extension to matplotlib that really helps make your plots look more appealing.\n",
    "- **`numpy`** (pronounced num-pie) is used for doing \"math stuff\", such as complex mathematical operations (e.g., square roots, exponents, logs), operations on matrices, and more. \n",
    "\n",
    "As we use these through the semester, their usefulness will become increasingly apparent.\n",
    "\n",
    "$~$\n",
    "\n",
    "To make the contents of a package available, you need to `import` it.  It is possible to import all or only a certain subset of a package's contents, depending on what we need.  It is also generally useful to create a shorthand label for packages when we import them (this will save you a lot of typing and make your code easier to read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is usually preferable to arrange imports by broad function\n",
    "# (e.g., all graphics imports in the same code block, all DS library\n",
    "#  imports in the same block, etc.), but for expository purposes the are\n",
    "# organized by import type.\n",
    "\n",
    "import os                        # full package imports\n",
    "import pipes        \n",
    "import math\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import numpy as np               # full package imports with aliases \n",
    "import pandas as pd\n",
    "import copy as cp   \n",
    "import seaborn as sns\n",
    "from icecream import ic \n",
    "\n",
    "import matplotlib.pylab as plt   # partial package imports with aliases \n",
    "\n",
    "# this trick is sometimes required to get plots to display inline with the rest of your notebook,\n",
    "# not in a separate window\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use package-specific things. For example, numpy has a function called `sqrt()` which will give us the square root of a numpy number. Since it is part of numpy, we need to tell Python that that's where it is by using a dot (e.g., `np.sqrt()`).\n",
    "\n",
    "In the following cell you can also see how to write **comments** in your code. Take my advice: write comments as you go.  It's helpful when you want to collaborate, then you don't have to figure out what you did to explain it to your collaborator.  But even more: often you need to come back to an analysis weeks, months, or even years later, and you will thank yourself for explaining what you did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_list = [0,0,1,2,3,3,4.5,7.6]\n",
    "print(some_list)\n",
    "some_dictionary = {'student1': '(929)-000-0000', 'student2': '(917)-000-0000', 'student3': '(470)-000-0000'}\n",
    "print(some_dictionary)\n",
    "some_set = set( [1,2,4,4,5,5] )\n",
    "print(some_set)\n",
    "\n",
    "\n",
    "# In this part of the code I am using numpy (np) functions\n",
    "\n",
    "print (\"Square root: \" + str ( np.sqrt(25) ))\n",
    "print (\"Maximum element of our previous list: \" + str( np.max(some_list) ))\n",
    "\n",
    "# In this part of the code I am using python functions\n",
    "\n",
    "print (\"Number of elements in our previous list: \" + str( len(some_list) ))\n",
    "print (\"Sum of elements in our previous list: \" + str( sum(some_list) ))\n",
    "print (\"Range of 5 numbers (remember we start with 0): \" + str( range(5) ))\n",
    "\n",
    "# #Bonus LIST COMPREHENSIONS\n",
    "# some_list_squared = [i*i for i in some_list]\n",
    "# #This is the same as:\n",
    "# some_list_squared_too = []\n",
    "# for i in some_list:\n",
    "#     some_list_squared_too.append(i*i)\n",
    "\n",
    "# print(f\"some_list_squared: {some_list_squared} = some_list_squared_too:{some_list_squared_too}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Palatino; font-size: 25px; color: purple\">  Custom (user-defined) helper functions </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there isn't a package to do exactly what we want, or sometimes, we might need to repeat the same sequence of operations many times.  In both cases, it is useful to write funcions for this.  In order to avoid cluttering up our notebooks, and to keep us focused on the main ideas of each lesson, we will define functions that are largely convenience or helper functions at the top of our notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `relabel(data, from_lab, to_lab, n)` to change label names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(data, from_lab, to_lab, n):\n",
    "    label_map = dict(zip(from_lab, to_lab))\n",
    "    new_labs = [None] * n\n",
    "    for i in range(n):\n",
    "        new_labs[i] = label_map.get(data[i])\n",
    "        \n",
    "    return new_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `count_words(s)` to count number of words in a text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def count_words(s):\n",
    "    word_list = s.split()\n",
    "    number_of_words = len(word_list)\n",
    "    return(number_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: Palatino; font-size: 30px; color: purple\">  Import the raw survey data and do quick-check of quality/structure</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  Let's see how to use the data science packages to do...Data Science!\n",
    "\n",
    "We can use `pandas` to import some data and keep it in a DS-friendly structure called a `DataFrame`.\n",
    "\n",
    "In this example, we will be looking at the responses from the pre-class survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"\"\n",
    "fn = \"responses.csv\"\n",
    "full_path= path+fn\n",
    "df = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data to see the variables we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh!  Right out of the gate we can see that the variable names are really long and cumbersome, and have spaces and other special charicters, which makes them difficult to use in computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive it, it would be useful to know what kind of data we have loaded.\n",
    "\n",
    "`pandas` makes it easy to get more detail on the a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh$^2$ !  Not only are the names cumbersome, but they make the output almost unreadable. \n",
    "\n",
    "Even so, we can see that some of the columns may contain personal identifying information, so we should drop those, along with any columns that are unlikely to be directly useful at this point.\n",
    "\n",
    "Let's start by dropping the variables we \"don't need.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['#', '*What is your first name?*', '*What is your NetID?*',\n",
    "                    '*Please use this space to provide any comments:*', 'Start Date (UTC)','Network ID'\n",
    "                   ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    " Now we can rename the columns that we do want to make things a bit easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_col_names = df.columns\n",
    "new_col_names = [\"degree\",     \"other_deg\",\n",
    "              \"cw_mvstats\", \"cw_python\",  \"cw_ML\",        \"cw_finance\",  \"cw_mgt\",     \"cw_strat\",\n",
    "              \"work_yrs\",\n",
    "              \"exp_stats\",  \"exp_python\",  \"exp_ML\",      \"exp_val\",     \"exp_deploy\", \"exp_prd_dev\", \"exp_prd_strat\", \n",
    "              \"did_OLS\",    \"did_RDB\",     \"did_cloud\",   \"did_API\", \n",
    "              \"comf_viz\",   \"comf_python\", \"comf_math\",   \"comf_stats\",  \"comf_ML\",    \"comf_strat\",\n",
    "              \"comf_term\",  \"comf_comm\",  \"comf_wrangle\", \n",
    "              \"intr_segm\",  \"intr_fraud\",  \"intr_invest\", \"intr_invnt\",  \"intr_QC\", \n",
    "              \"intr_recm\",  \"intr_risk\",   \"intr_supply\", \"intr_target\", \"intr_insur\", \"intr_other\",\n",
    "              \"obj_acc\",    \"obj_jobsrch\", \"obj_proj\",    \"obj_gen\",     \"obj_mgt_ds\", \"obj_startup\", \"obj_other\",\n",
    "              \"mcostly_sw\", \"warmup\",\n",
    "              \"sub_date\"\n",
    "             ]\n",
    "df.columns = new_col_names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the old and new variable names to see how much of a difference this makes for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(old_col_names, new_col_names), columns=[\"old\",\"new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That does seem a lot more manageable.  Look at rows `0`, `47`, and `48`, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to get some detail again, now that our variable names are pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's certainly better! \n",
    "\n",
    "Next we can take a look at what is actually *in* each variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sense of the class makeup by degree type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.degree.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's odd, there were 20 respondents but this histogram only shows 9.  We will need to sort that out.\n",
    "\n",
    "Let's take a look at respondents interest in Finance applications of DS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.intr_invest.hist(color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's odd: We only get a count for one category and many respondent are not represented.\n",
    "\n",
    "Let's take a look at that variable in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.intr_invest.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ugh again! It would appear that the for choice questions, like this one, the survey software just repeats the text of a category label in its export of the survey data.  For example, the question  we just examined, `intr_invest`, asked respondents to indicate whether they had interest in investment-related applications of DS.  In this case, the software export contains the label of that response option (\"Investment Methods\" in the field if the respondent had indicated interest, but it puts an `NaN` in that field for 'No', rather than simply creating a single variable indicating, e.g., a `0` or `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what kind of data is in some of the other variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)  # show the first 2 records of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we are not really ready yet to analyze this data set.\n",
    "\n",
    "We will need to do some work to get this data into shape first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: Palatino; font-size: 30px; color: purple\">Rudimentary data cleaning and recoding </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Palatino; font-size: 25px; color: purple\"> Relabel cumbersome (long) response labels from survey software</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by trying to relabel some of the very long data labels that the survey software provides.  Note that these are not variable names; they are the  values that a categorical variable can take in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Note definition of `relabel` in the Helper Functions section, above!\n",
    "\n",
    "n_resp = df.shape[0]\n",
    "\n",
    "# --- realable coursework cols\n",
    "coursework_labels_long  = [\"No prior coursework\",\n",
    "                           \"An undergraduate or graduate introductory course\",\n",
    "                           \"One or more advanced undergraduate courses\",\n",
    "                           \"One or more advanced Masters/PhD courses\"\n",
    "                          ]\n",
    "\n",
    "coursework_labels_short = [\"no courses\",\n",
    "                           \"intro\",\n",
    "                           \"adv_undergrad\",\n",
    "                           \"adv_grad\"\n",
    "                          ]\n",
    "\n",
    "# could be automated using prefix of col name\n",
    "coursework_columns = [\"cw_mvstats\", \"cw_python\", \"cw_ML\", \"cw_finance\", \"cw_mgt\", \"cw_strat\"]\n",
    "\n",
    "for col in coursework_columns:\n",
    "    df[col] = cp.copy(relabel(df[col], coursework_labels_long, coursework_labels_short, n_resp))\n",
    "    \n",
    "# -- relabel comfort cols\n",
    " \n",
    "comfort_labels_long  = [\"I've had no exposure\", \"I've had limited exposure\", \"I am somewhat comfortable\", \"I'm pretty good\", \"I'm very good\"]\n",
    "comfort_labels_short = [\"no exposure\", \"limited exposure\", \"somewhat comfortable\", \"pretty good\", \"very good\"]\n",
    "\n",
    "comfort_columns =      [\"comf_viz\",   \"comf_python\", \"comf_math\",   \"comf_stats\",  \"comf_ML\",   \n",
    "                        \"comf_strat\", \"comf_term\",  \"comf_comm\",  \"comf_wrangle\"\n",
    "]\n",
    "\n",
    "for col in comfort_columns:\n",
    "    df[col] = cp.copy(relabel(df[col], comfort_labels_long, comfort_labels_short, n_resp))\n",
    "\n",
    "experience_labels_long  = [\"No prior projects\", \"One small project\", \"A few projects\", \"A large project\", \"A number of large projects\"]\n",
    "experience_labels_short = [\"NONE\", \"SMALL\", \"MED\", \"LARGE\", \"LARGE+\"]\n",
    "\n",
    "experience_columns =      [\"exp_stats\", \"exp_python\", \"exp_ML\", \n",
    "                           \"exp_val\",   \"exp_deploy\", \"exp_prd_dev\", \n",
    "                           \"exp_prd_strat\"\n",
    "                          ]\n",
    "for col in experience_columns:\n",
    "    df[col] = cp.copy(relabel(df[col], experience_labels_long, experience_labels_short, n_resp))\n",
    "\n",
    "    \n",
    "# clean up survey software's long-text for \"Yes\" convention   \n",
    "\n",
    "\n",
    "YES = 1\n",
    "NO  = 0\n",
    "\n",
    "yesno_cols = [\"intr_segm\",   \"intr_fraud\", \"intr_invest\",\n",
    "              \"intr_invnt\",  \"intr_QC\",    \"intr_recm\",  \"intr_risk\",   \"intr_supply\",\n",
    "              \"intr_target\", \"intr_insur\", \"intr_other\", \"obj_acc\",     \"obj_jobsrch\",\n",
    "              \"obj_proj\",    \"obj_gen\",    \"obj_mgt_ds\", \"obj_startup\", \"obj_other\"\n",
    "             ]\n",
    "# yesno_cols = [ \"obj_startup\", \"obj_other\"]\n",
    "\n",
    "for col in yesno_cols:\n",
    "    df[col] =[YES if type(v) == str else NO for v in df[col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Palatino; font-size: 25px; color: purple\"> Transform  </span>  <span style=\"font-size: 20px\"> `sub_date` </span>  <span style=\"font-family: Palatino; font-size: 25px; color: purple\"> and </span><span style=\"font-size: 20px\">  `warmup`</span>  <span style=\"font-family: Palatino; font-size: 25px; color: purple\">to make them more useful </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sub_date`, the date on which the response was submitted is listed as a date, which is techncially OK for our learning algorithm, but it is not really set up for answering questions.  We can fix that by transforming it into a more useful quantity, for example, the number of days before the due date that the response was submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "HW_due_date   = dt.date(2022, 2, 7)\n",
    "\n",
    "spare_time = [ HW_due_date - dt.datetime.date(dt.datetime.strptime(d, '%Y-%m-%d %H:%M:%S')) for d in df.sub_date]\n",
    "hours_early = [d.total_seconds() / 3600 for d in spare_time]\n",
    "df = df.assign(hours_early=hours_early)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`warmup`,  the respondent's submission for the question regarding how to approach the hardware store chain's problem, could potentially be a fruitful source of text mining or even NLP insights, but that is a bit beyond our scope right now.  (In addition, for the algorithm we are going to demonstrate here, text values are not acceptable.)  For our purposes, we can transform that variable's values into something that is perhaps much cruder, but which might give us something easier to work with at this point, such as the number of words in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup_len = [len(s) for s in df.warmup]\n",
    "warmup_len = [count_words(s) for s in df.warmup]\n",
    "df = df.assign(warmup_len = warmup_len)\n",
    "long_warmup = [1 if s > np.median(warmup_len) else 0 for s in warmup_len]\n",
    "df = df.assign(long_warmup = long_warmup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally,  at least for this pass, we can drop the original raw columns since we will be using the transformed, rather than raw forms of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['sub_date', 'warmup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Palatino; font-size: 25px; color: purple\"> Clean up category names and coding </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's work on the categorical variables.  We can start with the columns dealing with the degrees that respondents are pursuing.  There are two of these:  `degree` and `other_deg`.  Let's look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(df.degree, df.other_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.degree =  df.degree.fillna(df.other_deg)\n",
    "df = df.drop(columns=[\"other_deg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#convert other categorical cols into categories and relabel for compactness\n",
    "cat_cols = [\"work_yrs\", \n",
    "              \"exp_stats\", \"exp_python\",  \"exp_ML\",      \"exp_val\",      \"exp_deploy\", \"exp_prd_dev\", \"exp_prd_strat\", \n",
    "              \"did_OLS\",   \"did_RDB\",     \"did_cloud\",    \"did_API\", \n",
    "              \"comf_viz\",  \"comf_python\", \"comf_math\",    \"comf_stats\",  \"comf_ML\",    \"comf_strat\",\n",
    "              \"comf_term\", \"comf_comm\",   \"comf_wrangle\"\n",
    "           ]\n",
    "\n",
    "for col in [cat_cols]:\n",
    "    df[col] = df[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: Palatino; font-size: 30px; color: purple\">  (Finally) Begin analysis: EDA </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Palatino; font-size: 25px; color: purple\">Basic EDA </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to look at the data to get a sense of how we want to explore it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rows, cols = 3, 3\n",
    "variables  = ['degree',     'work_yrs',   'hours_early', \n",
    "              'exp_stats',  'exp_python', 'exp_ML',\n",
    "              'comf_python','comf_math', 'comf_stats' \n",
    "             ]\n",
    "colors     = ['purple',    'gray',        'green', \n",
    "              'lightblue', 'lightblue',   'lightblue',\n",
    "              'lightgreen', 'lightgreen', 'lightgreen'\n",
    "             ]\n",
    "nvars      = len(variables)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(7*cols, 7*rows))\n",
    "axs      = axs.flatten()\n",
    "params   = {'axes.titlesize':'28', 'xtick.labelsize':'20', 'ytick.labelsize':'20'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "for i in range(nvars):\n",
    "    v = variables[i]\n",
    "    df[v].hist(ax = axs[i], color = colors[i])\n",
    "    axs[i].set_title(v)\n",
    "plt.show()    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Palatino; font-size: 25px; color: purple\">Intermediate EDA </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on, we'll learn about some tools to make this easier in python.  For example...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def create_explorer(eda_env, using_colab = False):\n",
    "    # if using Python 3.10 or higher, this can be done more elegantly with a `match` statement\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    def clear_previous_explorers(eda_modules):\n",
    "        for m in eda_modules:\n",
    "            try:\n",
    "                sys.modules.pop(m)\n",
    "            except:\n",
    "                None\n",
    "    # -----------------------------------------          \n",
    "         \n",
    "        \n",
    "    eda_modules = ['dataprep', 'pandas_profiling', 'bamboolib']\n",
    "    clear_previous_explorers(eda_modules)\n",
    "    \n",
    "    global explore\n",
    "    \n",
    "    if eda_env == \"dataprep\":\n",
    "        from dataprep.eda import create_report        \n",
    "        def explore(df, show = True):\n",
    "            report  = create_report(df)\n",
    "            report.show()\n",
    "            if show:\n",
    "                report.show()\n",
    "        return explore\n",
    "    elif eda_env == \"pandas_profiling\":\n",
    "        from pandas_profiling import ProfileReport\n",
    "        \n",
    "        def explore(df, show = True):\n",
    "            report = ProfileReport(df) \n",
    "            if show:\n",
    "                if using_colab:\n",
    "                    report.to_notebook_iframe()\n",
    "                else:\n",
    "                    report.to_notebook_iframe()\n",
    "                    # report.to_widgets()\n",
    "        return explore\n",
    "    elif eda_env == \"bamboo\":\n",
    "        \n",
    "        if using_colab:\n",
    "            print(\"WARNING: Cannot use bamboolib in Colab!  Null function returned.\")\n",
    "            explore = None\n",
    "        else:\n",
    "            import bamboolib\n",
    "            def explore(df, show = True):\n",
    "                if(show):\n",
    "                    return(df)\n",
    "            return explore\n",
    "    else:\n",
    "        print(\"WARNING: Unrecognized eda_env: \", + eda_env + \"  Null function returned.\")\n",
    "        explore = None\n",
    "        return explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "EDA_ENV = \"pandas_profiling\"\n",
    "USING_COLAB = False\n",
    "\n",
    "explore = create_explorer(EDA_ENV, USING_COLAB)\n",
    "explore(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bamboolib\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot to see here and even a cursory review of the report suggests that we would need to do some further _preprocessing_ of the data before modeling it.  (We will learn about this in the next lecture.\n",
    "\n",
    "But since this is just a fly-by introduction, we will move onto buiding our first data-driven model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: Palatino; font-size: 30px; color: purple\">Fitting a tree-based model</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a form of *recursive partitioning* algorithm to fit a tree model to the survey data.  To get our feet a little wet, let's see if we can figure out the features that are associated with a respondent having a longer vs. shorter response to the warmup question on the questionnaire...\n",
    "\n",
    "We can fit a model to use some of the other variables to try to explain `long_warmup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which variables we will be trying to \"predict\"\n",
    "target_col     = ['long_warmup']\n",
    "\n",
    "# select some variables to enter into the model to predict it\n",
    "predictor_cols = [\"comf_math\",   \n",
    "                  \"comf_stats\", \n",
    "                  \"hours_early\", \n",
    "                  \"degree\"\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the algorithm we will be using from `sklearn` does not acomodate text or label data, so we first need to massage the data to get it into a form that is conformable with the algorithm's requirements.  (Yup.  More data wrangling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df[predictor_cols], drop_first=False)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target_col]\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now we are ready to go..!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"font-family: Palatino; font-size: 25px; color: purple\">Estimate a tree model using </span>  <span style=\"font-size: 20px\"> `sklearn` </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will estimate our model in two steps.  These steps are, in general the same ones we will use for each estimation algorithm we study:\n",
    "1. **define a model object, with the structure and parameters we wish to use;** and\n",
    "2. **use the algorithm to estimate (fit) the parameters of the model, using a particular data set.**\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "np.random.seed(42) # so that we all get the same results\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\") \n",
    "decision_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitting algorithm will return an object that contains our the model we estimated, along with a number of useful members and methods that we may find useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... Not as revealing as we may have hoped.  It's sometimes easier to get a sense of the model by examining it graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "_ = tree.plot_tree(decision_tree, \n",
    "                   feature_names =X.columns, \n",
    "                   class_names   = ['shorter','longer'],\n",
    "                   impurity = False, proportion = True, precision = 1, \n",
    "                   rounded = False, fontsize = 16, filled = True\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting!  Now we can get a better sense of what the model is doing.\n",
    "\n",
    "The very first node seems to suggest that `days_early`, one of the derived variables we calculated during the import and preprocessing steps, is pretty predictive of warmup response length.\n",
    "\n",
    "Let's explore this in a bit more detail.\n",
    "\n",
    "Let's do a bit more data wrangling and then plot the average word length of a response based on the value of `days_early`.  The tree model suggested that values of `days_early` that are greater than about `35` were more likely to be associated with longer responses.  \n",
    "\n",
    "Let's go to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the data to make plotting a barplot easier\n",
    "\n",
    "df_plot_dat = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "Now let's take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "def cut(x, cutoff, below_lab, above_lab):\n",
    "    v  = [below_lab if h < cutoff else above_lab for h in df.hours_early]\n",
    "    return pd.Series(v)\n",
    "# -----------------------------------------\n",
    "\n",
    "params   = {'axes.titlesize':'28', 'xtick.labelsize':'18', 'ytick.labelsize':'18'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "rows, cols = 2, 2\n",
    "fig, ax  = plt.subplots(ncols = cols, nrows = rows, figsize = (9*cols, 9*rows))\n",
    "axs      = ax.ravel()\n",
    "\n",
    "cutoffs = [24, 36, 72, 96]\n",
    "pace = pd.Series([] * df.shape[0])\n",
    "df_plot_dat = df.assign(pace = pace)\n",
    "\n",
    "difs = np.zeros(len(cutoffs))\n",
    "\n",
    "for i, c in enumerate(cutoffs):\n",
    "    below_lab = \"rushed\"\n",
    "    above_lab = \"leisurely\"\n",
    "    pace = cut(df_plot_dat.warmup_len, c, above_lab, below_lab)     \n",
    "    df_plot_dat = df_plot_dat.assign(pace = pd.Series(pace))\n",
    "\n",
    "    title_txt = \"With more (less) than \" + str(c) + \" hrs. left\"\n",
    "\n",
    "    #subset the data using the `pandas` `groupby` method (and create the raw plot)\n",
    "    p = df_plot_dat.groupby(by = [\"pace\"])['warmup_len'].mean().plot(kind=\"bar\", ax = axs[i],\n",
    "                                                                 color=['green', 'red'],\n",
    "                                                                 title = title_txt, ylabel = \"word count\",\n",
    "                                                                 ylim = (0, 300),\n",
    "                                                                 xlabel = \"\", rot = 0, \n",
    "                                                                 grid = True\n",
    "                                                                )\n",
    "    p.set_ylabel(\"word count\",fontdict={'fontsize':20})\n",
    "    summary = df_plot_dat.groupby(by = [\"pace\"])['warmup_len'].mean()\n",
    "    difs[i] = summary[0] - summary[1]\n",
    "plt.show();\n",
    "\n",
    "\n",
    "\n",
    "dat = pd.DataFrame(data = {\"cutoffs\": cutoffs, \"difs\": difs})\n",
    "dat.plot(x = 'cutoffs', y = 'difs', figsize=(12, 5), color = \"red\",  linewidth=3)\n",
    "\n",
    "plt.xlabel(\"Hours before HW due\", fontsize = 20, fontweight = 'bold')\n",
    "plt.ylabel(\"Dif. in mean words\", fontsize = 20, fontweight = 'bold')\n",
    "plt.title(\"\\nAs the threshold is moved closer to the deadline, \\nboth lengths and differences got shorter\", fontsize = 30, fontweight = 'bold')\n",
    "plt.text(0, max(difs), \"Leisurly are longer\",    fontsize = 15, fontstyle = \"italic\", ma = \"right\")\n",
    "plt.text(0, min(difs)-10, \"Rushed are longer\", fontsize = 15, fontstyle = \"italic\", ma = \"right\")\n",
    "\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really cool new package for visualzing decision trees that saves us a bit of effort in the first pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "class_colors = [None, # 0 classes\n",
    "                None, # 1 class\n",
    "                [\"#ff6347\",\"#00ff80\"], # 2 classes\n",
    "]\n",
    "\n",
    "vis = dtreeviz(decision_tree,\n",
    "               X.iloc[:,:], y.iloc[:,0], # painful notation since dtreeviz\n",
    "               target_name=target_col,   # expects numpy data structures but\n",
    "               feature_names=X.columns,  # our data is in a pandas data frame\n",
    "               class_names=['shorter','longer'],\n",
    "               colors={'classes': class_colors}\n",
    "               \n",
    "              )\n",
    "\n",
    "vis.scale = 2.5\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FP's Supervised segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
